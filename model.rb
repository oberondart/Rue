require_relative "neural_net"
require "json"
=begin
network = NeuralNet.new([2, 6, 1])

xor_inputs = [
    [0.0, 0.0],
    [0.0, 1.0],
    [1.0, 0.0],
    [1.0, 1.0]
]

xor_outputs = [
    [0.0],
    [1.0],
    [1.0],
    [0.0]
]

100.times do 
	network.train(xor_inputs, xor_outputs, max_iterations: 10000)
end

puts "\nXOR Predictions:"
xor_inputs.each do |input|
  output = network.run(input)[0]
  puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nXOR Generalization test"
general_inputs = [
    [0.2, 0.2],
    [0.1, 0.9],
    [1.0, 0.2],
    [0.9, 0.9]
]

general_outputs = [
    [0.0],
    [1.0],
    [1.0],
    [0.0]
]

100.times do 
	network.train(general_inputs, general_outputs, max_iterations: 10000)
end

puts "\nTest predictions"
general_inputs.each do |input|
  output = network.run(input)[0]
  puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nAND XOR"
and_xor_network = NeuralNet.new([2, 6, 1])
and_xor = [
    [0.0, 0.0],
    [0.0, 1.0],
    [1.0, 0.0],
    [1.0, 1.0]
]

and_xor_outputs = [
    [0.0],
    [0.0],
    [0.0],
    [1.0]
]

100.times do 
    and_xor_network.train(and_xor,and_xor_outputs, max_iterations:10000)
end

puts "\nAND XOR Predictions"
and_xor.each do |input|
  output = and_xor_network.run(input)[0]
  puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nOR XOR"
or_xor_network = NeuralNet.new([2, 6, 1])

or_xor = [
    [0.0, 0.0],
    [0.0, 1.0],
    [1.0, 0.0],
    [1.0, 1.0]
]

or_xor_outputs = [
    [0.0],
    [1.0],
    [1.0],
    [1.0]
]

100.times do
    or_xor_network.train(or_xor, or_xor_outputs, max_iterations:10000)
end

puts "\nOR XOR Predictions"
or_xor.each do |input|
  output = or_xor_network.run(input)[0]
  puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nNAND GATE"

nand_network = NeuralNet.new([2, 6, 1])

nand_inputs = [
    [0.0, 0.0],
    [0.0, 1.0],
    [1.0, 0.0],
    [1.0, 1.0]
]

nand_outputs = [
    [1.0],
    [1.0],
    [1.0],
    [0.0]
]

100.times do
    nand_network.train(nand_inputs, nand_outputs, max_iterations:10000)
end

puts "\nNAND GATE PREDICTIONS"
nand_inputs.each do |input|
    output = nand_network.run(input)[0]
    puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nNOR GATE"

nor_network = NeuralNet.new([2, 6, 1])

nor_inputs = [
    [0.0, 0.0],
    [0.0, 1.0],
    [1.0, 0.0],
    [1.0, 1.0]
]

nor_outputs = [
    [1.0],
    [0.0],
    [0.0],
    [0.0]
]

100.times do
    nor_network.train(nor_inputs, nor_outputs, max_iterations:10000)
end

puts "\nNOR GATE PREDICTIONS"

nor_inputs.each do |input|
    output = nor_network.run(input)[0]
    puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nXNOR GATE"

xnor_network = NeuralNet.new([2, 6, 1])

xnor_inputs = [
    [0.0, 0.0],
    [0.0, 1.0],
    [1.0, 0.0],
    [1.0, 1.0]
]

xnor_outputs = [
    [1.0],
    [0.0],
    [0.0],
    [1.0]
]

100.times do
    xnor_network.train(xnor_inputs, xnor_outputs, max_iterations:10000)
end

puts "\nXNOR GATE PREDICTIONS"

xnor_inputs.each do |input|
    output = xnor_network.run(input)[0]
    puts "#{input.inspect} => #{output.round(3)}"
end

puts "\nMAX FUNCTION"

max_network = NeuralNet.new([2, 10, 1])

max_inputs = [
    [0.0, 0.0], [0.0, 0.5], [0.0, 1.0],
    [0.3, 0.7], [0.5, 0.2], [0.8, 0.4],
    [0.6, 0.6], [0.9, 0.3], [0.4, 0.9],
    [1.0, 0.0], [1.0, 0.5], [1.0, 1.0],
    [0.2, 0.8], [0.7, 0.1], [0.5, 0.5]
]

max_outputs = [
    [0.0], [0.5], [1.0],
    [0.7], [0.5], [0.8],
    [0.6], [0.9], [0.9],
    [1.0], [1.0], [1.0],
    [0.8], [0.7], [0.5]
]

100.times do
    max_network.train(max_inputs, max_outputs, max_iterations:10000)
end

puts "\nMAX FUNCTION PREDICTIONS"
max_inputs.each do |input|
  raw_output = max_network.run(input)[0]
  
  distance_to_first = (raw_output - input[0]).abs
  distance_to_second = (raw_output - input[1]).abs
  rounded_output = distance_to_first < distance_to_second ? input[0] : input[1]
  
  actual = [input[0], input[1]].max
  error = (rounded_output - actual).abs
  
  puts "  max(#{input[0]}, #{input[1]}) = #{raw_output.round(3)} ‚Üí #{rounded_output} (actual: #{actual}, error: #{error.round(4)})"
end

puts "\nMIN FUNCTION"

min_network = NeuralNet.new([2, 10, 1])

min_inputs = [
    [0.0, 0.0], [0.0, 0.5], [0.0, 1.0],
    [0.3, 0.7], [0.5, 0.2], [0.8, 0.4],
    [0.6, 0.6], [0.9, 0.3], [0.4, 0.9],
    [1.0, 0.0], [1.0, 0.5], [1.0, 1.0],
    [0.2, 0.8], [0.7, 0.1], [0.5, 0.5]
]

min_outputs = [
    [0.0], [0.0], [0.0],
    [0.3], [0.2], [0.4],
    [0.6], [0.3], [0.4],
    [0.0], [0.5], [1.0],
    [0.2], [0.1], [0.5]
]

100.times do
    min_network.train(min_inputs, min_outputs, max_iterations:10000)
end

puts "\nMIN FUNCTION PREDICTIONS"
min_inputs.each do |input|
  raw_output = min_network.run(input)[0]
  
  distance_to_first = (raw_output - input[0]).abs
  distance_to_second = (raw_output - input[1]).abs
  rounded_output = distance_to_first < distance_to_second ? input[0] : input[1]
  
  actual = [input[0], input[1]].min
  error = (rounded_output - actual).abs
  
  puts "  min(#{input[0]}, #{input[1]}) = #{raw_output.round(3)} ‚Üí #{rounded_output} (actual: #{actual}, error: #{error.round(4)})"
end

# ITERATIVE PROGRESSIVE SNAPPING - Round step-by-step until we reach the correct answer
def iterative_snap_to_correct(predicted, valid_outputs, actual, max_steps: 10)
  steps = [predicted]
  current = predicted
  
  max_steps.times do
    # Snap to nearest valid
    snapped = valid_outputs.min_by { |valid| (current - valid).abs }
    steps << snapped
    
    # If we hit the target, stop
    if (snapped - actual).abs < 0.01
      return { final: snapped, steps: steps, success: true }
    end
    
    # Calculate direction to move
    error = actual - snapped
    
    # Find next valid output in the direction we need to go
    if error > 0
      # Need to go UP
      next_valid = valid_outputs.select { |v| v > snapped }.min
    else
      # Need to go DOWN
      next_valid = valid_outputs.select { |v| v < snapped }.max
    end
    
    # If no next valid in that direction, we're stuck
    if next_valid.nil?
      # Try pushing current value in the right direction
      current = current + (error * 0.5)
      steps << current
    else
      # Move current toward next valid
      current = (current + next_valid) / 2.0
      steps << current
    end
  end
  
  # Final snap
  final = valid_outputs.min_by { |valid| (current - valid).abs }
  { final: final, steps: steps, success: (final - actual).abs < 0.01 }
end

puts "\n" + "="*80
puts "ADDITION MODEL - ITERATIVE PROGRESSIVE SNAPPING"
puts "="*80

addition_network = NeuralNet.new([2, 45, 45, 1])

addition_inputs = [
  [0.1, 0.2], [0.2, 0.3], [0.3, 0.4],
  [0.4, 0.5], [0.5, 0.5], [0.6, 0.4],
  [0.7, 0.3], [0.8, 0.2], [0.9, 0.1],
  [0.0, 0.5], [0.5, 0.0], [1.0, 0.0],
  [0.3, 0.6], [0.4, 0.4], [0.2, 0.7]
]

valid_addition_sums = addition_inputs.map { |i| i[0] + i[1] }.uniq.sort
puts "Valid addition outputs: #{valid_addition_sums.map { |x| x.round(2) }.inspect}"

addition_outputs = addition_inputs.map { |input| [(input[0] + input[1])] }

puts "\nIterative Progressive Snapping Training"

base_iterations = 500
max_rounds = 5

max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  # Train on correct answers
  base_iterations.times do
    addition_network.train(addition_inputs, addition_outputs, max_iterations: 10000)
  end
  
  # Evaluate with iterative snapping
  errors = []
  wrong_cases = []
  addition_inputs.each_with_index do |input, i|
    predicted = addition_network.run(input)[0]
    actual = input[0] + input[1]
    result = iterative_snap_to_correct(predicted, valid_addition_sums, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  # Train on PROGRESSIVE TARGETS from iterative snapping
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      i = case_data[:index]
      input = addition_inputs[i]
      actual = input[0] + input[1]
      steps = case_data[:result][:steps]
      
      # Create progressive training targets along the path
      # Each step should move closer to the correct answer
      steps.each_with_index do |step, step_idx|
        # Calculate how far along the path we are
        progress = (step_idx + 1).to_f / steps.length
        
        # Create target that's between current step and actual answer
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << input
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    [#{input[0]}, #{input[1]}]: #{steps.length} steps ‚Üí #{case_data[:result][:final].round(2)} (need #{actual.round(2)})"
    end
    
    # Train on ALL progressive targets
    1500.times do
      addition_network.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    # Also reinforce correct answers
    400.times do
      addition_network.train(addition_inputs, addition_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ ADDITION PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 100
end

puts "\nADDITION PREDICTIONS (Final with Iterative Snapping Path)"
addition_inputs.each do |input|
  predicted = addition_network.run(input)[0]
  actual = input[0] + input[1]
  result = iterative_snap_to_correct(predicted, valid_addition_sums, actual)
  
  error = (result[:final] - actual).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  
  # Show the snapping path
  path_str = result[:steps][0..3].map { |s| s.round(3) }.join(" ‚Üí ")
  if result[:steps].length > 4
    path_str += " ‚Üí ... ‚Üí #{result[:final].round(2)}"
  else
    path_str += " ‚Üí #{result[:final].round(2)}"
  end
  
  puts "  #{marker} #{input[0]} + #{input[1]} = #{path_str} (actual: #{actual.round(2)}, error: #{error.round(4)})"
end

puts "\n" + "="*80
puts "SUBTRACTION MODEL - ITERATIVE PROGRESSIVE SNAPPING"
puts "="*80

subtraction_nn = NeuralNet.new([2, 45, 45, 1])

subtraction_inputs = [
  [0.5, 0.2], [0.6, 0.3], [0.7, 0.4],
  [0.8, 0.5], [0.9, 0.6], [1.0, 0.7],
  [0.4, 0.1], [0.5, 0.3], [0.6, 0.2],
  [0.3, 0.3], [0.7, 0.7], [1.0, 1.0],
  [1.0, 0.5], [0.8, 0.3], [0.9, 0.4]
]

valid_subtraction_diffs = subtraction_inputs.map { |i| i[0] - i[1] }.uniq.sort
puts "Valid subtraction outputs: #{valid_subtraction_diffs.map { |x| x.round(2) }.inspect}"

subtraction_outputs = subtraction_inputs.map { |input| [(input[0] - input[1])] }

puts "\nIterative Progressive Snapping Training"

base_iterations = 400
max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    subtraction_nn.train(subtraction_inputs, subtraction_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  subtraction_inputs.each_with_index do |input, i|
    predicted = subtraction_nn.run(input)[0]
    actual = input[0] - input[1]
    result = iterative_snap_to_correct(predicted, valid_subtraction_diffs, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      i = case_data[:index]
      input = subtraction_inputs[i]
      actual = input[0] - input[1]
      steps = case_data[:result][:steps]
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << input
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    [#{input[0]}, #{input[1]}]: #{steps.length} steps ‚Üí #{case_data[:result][:final].round(2)} (need #{actual.round(2)})"
    end
    
    1500.times do
      subtraction_nn.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      subtraction_nn.train(subtraction_inputs, subtraction_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ SUBTRACTION PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 50
end

puts "\nSUBTRACTION PREDICTIONS (Final with Iterative Snapping Path)"
subtraction_inputs.each do |input|
  predicted = subtraction_nn.run(input)[0]
  actual = input[0] - input[1]
  result = iterative_snap_to_correct(predicted, valid_subtraction_diffs, actual)
  
  error = (result[:final] - actual).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  
  path_str = result[:steps][0..3].map { |s| s.round(3) }.join(" ‚Üí ")
  if result[:steps].length > 4
    path_str += " ‚Üí ... ‚Üí #{result[:final].round(2)}"
  else
    path_str += " ‚Üí #{result[:final].round(2)}"
  end
  
  puts "  #{marker} #{input[0]} - #{input[1]} = #{path_str} (actual: #{actual.round(2)}, error: #{error.round(4)})"
end

puts "\n" + "="*80
puts "MULTIPLICATION MODEL - ITERATIVE PROGRESSIVE SNAPPING"
puts "="*80

multiplication_nn = NeuralNet.new([2, 100, 1])

multiplication_inputs = [
  [0.2, 0.3], [0.3, 0.4], [0.4, 0.5],
  [0.5, 0.6], [0.6, 0.7], [0.7, 0.8],
  [0.2, 0.5], [0.3, 0.6], [0.4, 0.7],
  [0.1, 0.5], [0.2, 0.8], [0.3, 0.9],
  [0.5, 0.5], [0.8, 0.8], [0.9, 0.9]
]

valid_multiplication_products = multiplication_inputs.map { |i| i[0] * i[1] }.uniq.sort
puts "Valid multiplication outputs: #{valid_multiplication_products.map { |x| x.round(3) }.inspect}"

multiplication_outputs = multiplication_inputs.map { |input| [(input[0] * input[1])] }

puts "\nIterative Progressive Snapping Training"

base_iterations = 400
max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    multiplication_nn.train(multiplication_inputs, multiplication_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  multiplication_inputs.each_with_index do |input, i|
    predicted = multiplication_nn.run(input)[0]
    actual = input[0] * input[1]
    result = iterative_snap_to_correct(predicted, valid_multiplication_products, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      i = case_data[:index]
      input = multiplication_inputs[i]
      actual = input[0] * input[1]
      steps = case_data[:result][:steps]
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << input
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    [#{input[0]}, #{input[1]}]: #{steps.length} steps ‚Üí #{case_data[:result][:final].round(3)} (need #{actual.round(3)})"
    end
    
    1500.times do
      multiplication_nn.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      multiplication_nn.train(multiplication_inputs, multiplication_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ MULTIPLICATION PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 50
end

puts "\nMULTIPLICATION PREDICTIONS (Final with Iterative Snapping Path)"
multiplication_inputs.each do |input|
  predicted = multiplication_nn.run(input)[0]
  actual = input[0] * input[1]
  result = iterative_snap_to_correct(predicted, valid_multiplication_products, actual)
  
  error = (result[:final] - actual).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  
  path_str = result[:steps][0..3].map { |s| s.round(3) }.join(" ‚Üí ")
  if result[:steps].length > 4
    path_str += " ‚Üí ... ‚Üí #{result[:final].round(3)}"
  else
    path_str += " ‚Üí #{result[:final].round(3)}"
  end
  
  puts "  #{marker} #{input[0]} √ó #{input[1]} = #{path_str} (actual: #{actual.round(3)}, error: #{error.round(4)})"
end

# Helper for iterative progressive snapping

def iterative_snap_to_correct(predicted, valid_outputs, actual, max_steps: 10)
  steps = [predicted]
  current = predicted
  
  max_steps.times do
    # Snap to nearest valid
    snapped = valid_outputs.min_by { |valid| (current - valid).abs }
    steps << snapped
    
    # If we hit the target, stop
    if (snapped - actual).abs < 0.01
      return { final: snapped, steps: steps, success: true }
    end
    
    # Calculate direction to move
    error = actual - snapped
    
    # Find next valid output in the direction we need to go
    if error > 0
      # Need to go UP
      next_valid = valid_outputs.select { |v| v > snapped }.min
    else
      # Need to go DOWN
      next_valid = valid_outputs.select { |v| v < snapped }.max
    end
    
    # If no next valid in that direction, we're stuck
    if next_valid.nil?
      # Try pushing current value in the right direction
      current = current + (error * 0.5)
      steps << current
    else
      # Move current toward next valid
      current = (current + next_valid) / 2.0
      steps << current
    end
  end
  
  # Final snap
  final = valid_outputs.min_by { |valid| (current - valid).abs }
  { final: final, steps: steps, success: (final - actual).abs < 0.01 }
end

puts "\n" + "="*80
puts "DIVISION MODEL - WHOLE NUMBER THINKING IN DECIMAL FORM"
puts "="*80
puts "Concept: 8 √∑ 2 = 4, but we represent 8 as 0.8, 2 as 0.2, and 4 as 0.4"
puts "This keeps everything in the 0-1 range the network loves!"
puts "="*80

division_network = NeuralNet.new([2, 60, 60, 1])

# Division examples: Think whole numbers but represent as decimals!
# Format: [dividend, divisor] ‚Üí quotient (all as decimals)
division_inputs = [
  [0.8, 0.2],  # 8 √∑ 2 = 4 ‚Üí 0.4
  [0.6, 0.2],  # 6 √∑ 2 = 3 ‚Üí 0.3
  [0.9, 0.3],  # 9 √∑ 3 = 3 ‚Üí 0.3
  [0.6, 0.3],  # 6 √∑ 3 = 2 ‚Üí 0.2
  [0.8, 0.4],  # 8 √∑ 4 = 2 ‚Üí 0.2
  [1.0, 0.5],  # 10 √∑ 5 = 2 ‚Üí 0.2
  [0.5, 0.5],  # 5 √∑ 5 = 1 ‚Üí 0.1
  [0.4, 0.2],  # 4 √∑ 2 = 2 ‚Üí 0.2
  [1.0, 0.2],  # 10 √∑ 2 = 5 ‚Üí 0.5
  [0.8, 0.1],  # 8 √∑ 1 = 8 ‚Üí 0.8
  [0.3, 0.3],  # 3 √∑ 3 = 1 ‚Üí 0.1
  [0.6, 0.1],  # 6 √∑ 1 = 6 ‚Üí 0.6
  [0.4, 0.4],  # 4 √∑ 4 = 1 ‚Üí 0.1
  [0.9, 0.1],  # 9 √∑ 1 = 9 ‚Üí 0.9
  [0.7, 0.7],  # 7 √∑ 7 = 1 ‚Üí 0.1
]

# Calculate outputs: dividend √∑ divisor (thinking whole numbers)
division_outputs = division_inputs.map do |input|
  dividend = (input[0] * 10).round  # 0.8 ‚Üí 8
  divisor = (input[1] * 10).round   # 0.2 ‚Üí 2
  quotient = dividend / divisor     # 8 √∑ 2 = 4
  output = quotient / 10.0          # 4 ‚Üí 0.4
  [output]
end

# Show what we're learning
puts "\nDivision Training Set (Whole Number Thinking):"
division_inputs.each_with_index do |input, i|
  dividend_whole = (input[0] * 10).round
  divisor_whole = (input[1] * 10).round
  quotient_whole = division_outputs[i][0] * 10
  puts "  #{input[0]} √∑ #{input[1]} ‚Üí #{division_outputs[i][0]} (thinking: #{dividend_whole} √∑ #{divisor_whole} = #{quotient_whole.round})"
end

valid_division_results = division_outputs.map { |o| o[0] }.uniq.sort
puts "\nValid division outputs: #{valid_division_results.map { |x| x.round(2) }.inspect}"

puts "\nIterative Progressive Snapping Training"

base_iterations = 500
max_rounds = 5

max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    division_network.train(division_inputs, division_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  division_inputs.each_with_index do |input, i|
    predicted = division_network.run(input)[0]
    actual = division_outputs[i][0]
    result = iterative_snap_to_correct(predicted, valid_division_results, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      i = case_data[:index]
      input = division_inputs[i]
      actual = division_outputs[i][0]
      steps = case_data[:result][:steps]
      
      dividend_whole = (input[0] * 10).round
      divisor_whole = (input[1] * 10).round
      quotient_whole = (actual * 10).round
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << input
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    #{input[0]} √∑ #{input[1]}: #{steps.length} steps ‚Üí #{case_data[:result][:final].round(2)} (need #{actual.round(2)}) | {#{dividend_whole} √∑ #{divisor_whole} = #{quotient_whole}}"
    end
    
    1500.times do
      division_network.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      division_network.train(division_inputs, division_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ DIVISION PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 100
end

puts "\n" + "="*80
puts "DIVISION PREDICTIONS (Final with Iterative Snapping Path)"
puts "="*80

division_inputs.each_with_index do |input, i|
  predicted = division_network.run(input)[0]
  actual = division_outputs[i][0]
  result = iterative_snap_to_correct(predicted, valid_division_results, actual)
  
  error = (result[:final] - actual).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  
  # Show whole number interpretation
  dividend_whole = (input[0] * 10).round
  divisor_whole = (input[1] * 10).round
  quotient_whole = (result[:final] * 10).round
  actual_whole = (actual * 10).round
  
  path_str = result[:steps][0..3].map { |s| s.round(3) }.join(" ‚Üí ")
  if result[:steps].length > 4
    path_str += " ‚Üí ... ‚Üí #{result[:final].round(2)}"
  else
    path_str += " ‚Üí #{result[:final].round(2)}"
  end
  
  puts "  #{marker} #{input[0]} √∑ #{input[1]} = #{path_str} (actual: #{actual.round(2)}, error: #{error.round(4)})"
  puts "      Thinking: #{dividend_whole} √∑ #{divisor_whole} = #{quotient_whole} (should be #{actual_whole})"
end


exponent_inputs = [
  [0.1, 0.2],  # 1¬≤ = 1 ‚Üí 0.01
  [0.2, 0.2],  # 2¬≤ = 4 ‚Üí 0.04
  [0.3, 0.2],  # 3¬≤ = 9 ‚Üí 0.09
  [0.4, 0.2],  # 4¬≤ = 16 ‚Üí 0.16
  [0.5, 0.2],  # 5¬≤ = 25 ‚Üí 0.25
  [0.6, 0.2],  # 6¬≤ = 36 ‚Üí 0.36
  [0.7, 0.2],  # 7¬≤ = 49 ‚Üí 0.49
  [0.8, 0.2],  # 8¬≤ = 64 ‚Üí 0.64
  [0.9, 0.2],  # 9¬≤ = 81 ‚Üí 0.81
  [1.0, 0.2],  # 10¬≤ = 100 ‚Üí 1.00
]

# Calculate outputs
exponent_outputs = exponent_inputs.map do |input|
  base_whole = (input[0] * 10).round
  exponent_value = 2  # Always squaring for now
  result = base_whole ** exponent_value
  output = result / 100.0  # Scale to 0-1
  [output]
end

def iterative_snap_to_correct(predicted, valid_outputs, actual, max_steps: 10)
  steps = [predicted]
  current = predicted
  
  max_steps.times do
    # Snap to nearest valid
    snapped = valid_outputs.min_by { |valid| (current - valid).abs }
    steps << snapped
    
    # If we hit the target, stop
    if (snapped - actual).abs < 0.01
      return { final: snapped, steps: steps, success: true }
    end
    
    # Calculate direction to move
    error = actual - snapped
    
    # Find next valid output in the direction we need to go
    if error > 0
      # Need to go UP
      next_valid = valid_outputs.select { |v| v > snapped }.min
    else
      # Need to go DOWN
      next_valid = valid_outputs.select { |v| v < snapped }.max
    end
    
    # If no next valid in that direction, we're stuck
    if next_valid.nil?
      # Try pushing current value in the right direction
      current = current + (error * 0.5)
      steps << current
    else
      # Move current toward next valid
      current = (current + next_valid) / 2.0
      steps << current
    end
  end
  
  # Final snap
  final = valid_outputs.min_by { |valid| (current - valid).abs }
  { final: final, steps: steps, success: (final - actual).abs < 0.01 }
end

puts "\n" + "="*80
puts "EXPONENT MODEL - SQUARES WITH /100 MAPPING"
puts "="*80
puts "Concept: n¬≤ = result, but we represent n as 0.n and result as result/100"
puts "Example: 5¬≤ = 25, input 0.5, output 0.25"
puts "This keeps everything in the 0-1 range!"
puts "="*80

exponent_network = NeuralNet.new([2, 60, 60, 1])

# Exponent examples: Squares with /100 mapping
# Format: [base, exponent_indicator] ‚Üí output
# Base: 0.1-1.0 representing 1-10
# Exponent: 0.2 (representing power of 2, i.e., squaring)
# Output: result/100

exponent_inputs = [
  [0.1, 0.2],  # 1¬≤ = 1 ‚Üí 0.01
  [0.2, 0.2],  # 2¬≤ = 4 ‚Üí 0.04
  [0.3, 0.2],  # 3¬≤ = 9 ‚Üí 0.09
  [0.4, 0.2],  # 4¬≤ = 16 ‚Üí 0.16
  [0.5, 0.2],  # 5¬≤ = 25 ‚Üí 0.25
  [0.6, 0.2],  # 6¬≤ = 36 ‚Üí 0.36
  [0.7, 0.2],  # 7¬≤ = 49 ‚Üí 0.49
  [0.8, 0.2],  # 8¬≤ = 64 ‚Üí 0.64
  [0.9, 0.2],  # 9¬≤ = 81 ‚Üí 0.81
  [1.0, 0.2],  # 10¬≤ = 100 ‚Üí 1.00
]

# Calculate outputs: base¬≤ / 100
exponent_outputs = exponent_inputs.map do |input|
  base_whole = (input[0] * 10).round     # 0.5 ‚Üí 5
  exponent_value = 2                      # Always squaring
  result = base_whole ** exponent_value   # 5¬≤ = 25
  output = result / 100.0                 # 25 ‚Üí 0.25
  [output]
end

# Show what we're learning
puts "\nExponent Training Set (Squares with /100 Mapping):"
exponent_inputs.each_with_index do |input, i|
  base_whole = (input[0] * 10).round
  result_whole = exponent_outputs[i][0] * 100
  puts "  #{input[0]}¬≤ ‚Üí #{exponent_outputs[i][0]} (thinking: #{base_whole}¬≤ = #{result_whole.round})"
end

valid_exponent_results = exponent_outputs.map { |o| o[0] }.uniq.sort
puts "\nValid exponent outputs: #{valid_exponent_results.map { |x| x.round(2) }.inspect}"

puts "\nIterative Progressive Snapping Training"

base_iterations = 400
max_rounds = 30

max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    exponent_network.train(exponent_inputs, exponent_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  exponent_inputs.each_with_index do |input, i|
    predicted = exponent_network.run(input)[0]
    actual = exponent_outputs[i][0]
    result = iterative_snap_to_correct(predicted, valid_exponent_results, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      i = case_data[:index]
      input = exponent_inputs[i]
      actual = exponent_outputs[i][0]
      steps = case_data[:result][:steps]
      
      base_whole = (input[0] * 10).round
      result_whole = (actual * 100).round
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << input
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    #{input[0]}¬≤: #{steps.length} steps ‚Üí #{case_data[:result][:final].round(2)} (need #{actual.round(2)}) | {#{base_whole}¬≤ = #{result_whole}}"
    end
    
    1500.times do
      exponent_network.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      exponent_network.train(exponent_inputs, exponent_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ EXPONENT PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 50
end

puts "\n" + "="*80
puts "EXPONENT PREDICTIONS (Final with Iterative Snapping Path)"
puts "="*80

exponent_inputs.each_with_index do |input, i|
  predicted = exponent_network.run(input)[0]
  actual = exponent_outputs[i][0]
  result = iterative_snap_to_correct(predicted, valid_exponent_results, actual)
  
  error = (result[:final] - actual).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  
  # Show whole number interpretation
  base_whole = (input[0] * 10).round
  result_whole = (result[:final] * 100).round
  actual_whole = (actual * 100).round
  
  path_str = result[:steps][0..3].map { |s| s.round(3) }.join(" ‚Üí ")
  if result[:steps].length > 4
    path_str += " ‚Üí ... ‚Üí #{result[:final].round(2)}"
  else
    path_str += " ‚Üí #{result[:final].round(2)}"
  end
  
  puts "  #{marker} #{input[0]}¬≤ = #{path_str} (actual: #{actual.round(2)}, error: #{error.round(4)})"
  puts "      Thinking: #{base_whole}¬≤ = #{result_whole} (should be #{actual_whole})"
end

puts "\n" + "="*80
puts "TEXT-BASED BOOLEAN LOGIC - ONE-HOT ENCODING"
puts "="*80
puts "Revolutionary: Training neural networks with TEXT inputs!"
puts "Encoding: 'true' ‚Üí [1.0, 0.0], 'false' ‚Üí [0.0, 1.0]"
puts "="*80

# One-hot encoding functions
def encode_bool(text)
  case text.downcase
  when "true"
    [1.0, 0.0]
  when "false"
    [0.0, 1.0]
  when "yes"
    [1.0, 0.0]
  when "no"  
    [0.0, 1.0]
  else
    raise "Unknown boolean value: #{text}"
  end
end

def decode_bool(vector)
  # Find which position has the higher value
  if vector[0] > vector[1]
    "true"
  else
    "false"
  end
end

# Snap to nearest valid one-hot encoding
def snap_to_one_hot(vector)
  if vector[0] > vector[1]
    [1.0, 0.0]
  else
    [0.0, 1.0]
  end
end

puts "\n" + "="*80
puts "AND GATE - Text Input Version"
puts "="*80

text_and_network = NeuralNet.new([4, 6, 2])  # 4 inputs (2 booleans √ó 2 one-hot), 2 outputs

text_and_text_inputs = [
  ["false", "false"],
  ["false", "true"],
  ["true", "false"],
  ["true", "true"]
]

text_and_text_outputs = [
  "false",
  "false",
  "false",
  "true"
]

# Encode to vectors
text_and_inputs = text_and_text_inputs.map { |pair| encode_bool(pair[0]) + encode_bool(pair[1]) }
text_and_outputs = text_and_text_outputs.map { |text| encode_bool(text) }

puts "\nTraining AND gate with text..."
100.times do
  text_and_network.train(text_and_inputs, text_and_outputs, max_iterations: 10000)
end

puts "\nAND GATE PREDICTIONS:"
text_and_text_inputs.each_with_index do |pair, i|
  input_vector = text_and_inputs[i]
  output_vector = text_and_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted_text = decode_bool(snapped)
  actual_text = text_and_text_outputs[i]
  
  marker = predicted_text == actual_text ? "‚úì" : "‚úó"
  puts "  #{marker} \"#{pair[0]}\" AND \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted_text}\" (actual: \"#{actual_text}\")"
end

puts "\n" + "="*80
puts "OR GATE - Text Input Version"
puts "="*80

text_or_network = NeuralNet.new([4, 6, 2])

text_or_text_inputs = [
  ["false", "false"],
  ["false", "true"],
  ["true", "false"],
  ["true", "true"]
]

text_or_text_outputs = [
  "false",
  "true",
  "true",
  "true"
]

text_or_inputs = text_or_text_inputs.map { |pair| encode_bool(pair[0]) + encode_bool(pair[1]) }
text_or_outputs = text_or_text_outputs.map { |text| encode_bool(text) }

puts "\nTraining OR gate with text..."
100.times do
  text_or_network.train(text_or_inputs, text_or_outputs, max_iterations: 10000)
end

puts "\nOR GATE PREDICTIONS:"
text_or_text_inputs.each_with_index do |pair, i|
  input_vector = text_or_inputs[i]
  output_vector = text_or_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted_text = decode_bool(snapped)
  actual_text = text_or_text_outputs[i]
  
  marker = predicted_text == actual_text ? "‚úì" : "‚úó"
  puts "  #{marker} \"#{pair[0]}\" OR \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted_text}\" (actual: \"#{actual_text}\")"
end

puts "\n" + "="*80
puts "XOR GATE - Text Input Version"
puts "="*80

text_xor_network = NeuralNet.new([4, 6, 2])

text_xor_text_inputs = [
  ["false", "false"],
  ["false", "true"],
  ["true", "false"],
  ["true", "true"]
]

text_xor_text_outputs = [
  "false",
  "true",
  "true",
  "false"
]

text_xor_inputs = text_xor_text_inputs.map { |pair| encode_bool(pair[0]) + encode_bool(pair[1]) }
text_xor_outputs = text_xor_text_outputs.map { |text| encode_bool(text) }

puts "\nTraining XOR gate with text..."
100.times do
  text_xor_network.train(text_xor_inputs, text_xor_outputs, max_iterations: 10000)
end

puts "\nXOR GATE PREDICTIONS:"
text_xor_text_inputs.each_with_index do |pair, i|
  input_vector = text_xor_inputs[i]
  output_vector = text_xor_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted_text = decode_bool(snapped)
  actual_text = text_xor_text_outputs[i]
  
  marker = predicted_text == actual_text ? "‚úì" : "‚úó"
  puts "  #{marker} \"#{pair[0]}\" XOR \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted_text}\" (actual: \"#{actual_text}\")"
end

puts "\n" + "="*80
puts "NOT GATE - Text Input Version (Single Input!)"
puts "="*80

text_not_network = NeuralNet.new([2, 4, 2])  # 2 inputs (1 boolean √ó 2 one-hot), 2 outputs

text_not_text_inputs = [
  ["false"],
  ["true"]
]

text_not_text_outputs = [
  "true",
  "false"
]

text_not_inputs = text_not_text_inputs.map { |arr| encode_bool(arr[0]) }
text_not_outputs = text_not_text_outputs.map { |text| encode_bool(text) }

puts "\nTraining NOT gate with text..."
100.times do
  text_not_network.train(text_not_inputs, text_not_outputs, max_iterations: 10000)
end

puts "\nNOT GATE PREDICTIONS:"
text_not_text_inputs.each_with_index do |arr, i|
  input_vector = text_not_inputs[i]
  output_vector = text_not_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted_text = decode_bool(snapped)
  actual_text = text_not_text_outputs[i]
  
  marker = predicted_text == actual_text ? "‚úì" : "‚úó"
  puts "  #{marker} NOT \"#{arr[0]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted_text}\" (actual: \"#{actual_text}\")"
end

puts "\n" + "="*80
puts "NAND GATE - Text Input Version"
puts "="*80

text_nand_network = NeuralNet.new([4, 6, 2])

text_nand_text_inputs = [
  ["false", "false"],
  ["false", "true"],
  ["true", "false"],
  ["true", "true"]
]

text_nand_text_outputs = [
  "true",
  "true",
  "true",
  "false"
]

text_nand_inputs = text_nand_text_inputs.map { |pair| encode_bool(pair[0]) + encode_bool(pair[1]) }
text_nand_outputs = text_nand_text_outputs.map { |text| encode_bool(text) }

puts "\nTraining NAND gate with text..."
100.times do
  text_nand_network.train(text_nand_inputs, text_nand_outputs, max_iterations: 10000)
end

puts "\nNAND GATE PREDICTIONS:"
text_nand_text_inputs.each_with_index do |pair, i|
  input_vector = text_nand_inputs[i]
  output_vector = text_nand_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted_text = decode_bool(snapped)
  actual_text = text_nand_text_outputs[i]
  
  marker = predicted_text == actual_text ? "‚úì" : "‚úó"
  puts "  #{marker} \"#{pair[0]}\" NAND \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted_text}\" (actual: \"#{actual_text}\")"
end

puts "\n" + "="*80
puts "NOR GATE - Text Input Version"
puts "="*80

text_nor_network = NeuralNet.new([4, 6, 2])

text_nor_text_inputs = [
  ["false", "false"],
  ["false", "true"],
  ["true", "false"],
  ["true", "true"]
]

text_nor_text_outputs = [
  "true",
  "false",
  "false",
  "false"
]

text_nor_inputs = text_nor_text_inputs.map { |pair| encode_bool(pair[0]) + encode_bool(pair[1]) }
text_nor_outputs = text_nor_text_outputs.map { |text| encode_bool(text) }

puts "\nTraining NOR gate with text..."
100.times do
  text_nor_network.train(text_nor_inputs, text_nor_outputs, max_iterations: 10000)
end

puts "\nNOR GATE PREDICTIONS:"
text_nor_text_inputs.each_with_index do |pair, i|
  input_vector = text_nor_inputs[i]
  output_vector = text_nor_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted_text = decode_bool(snapped)
  actual_text = text_nor_text_outputs[i]
  
  marker = predicted_text == actual_text ? "‚úì" : "‚úó"
  puts "  #{marker} \"#{pair[0]}\" NOR \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted_text}\" (actual: \"#{actual_text}\")"
end

puts "\n" + "="*80
puts "SUMMARY - TEXT-BASED BOOLEAN LOGIC"
puts "="*80

# Count successes
all_networks = [
  { name: "AND", inputs: text_and_text_inputs, outputs: text_and_text_outputs, network: text_and_network, encoded_inputs: text_and_inputs },
  { name: "OR", inputs: text_or_text_inputs, outputs: text_or_text_outputs, network: text_or_network, encoded_inputs: text_or_inputs },
  { name: "XOR", inputs: text_xor_text_inputs, outputs: text_xor_text_outputs, network: text_xor_network, encoded_inputs: text_xor_inputs },
  { name: "NOT", inputs: text_not_text_inputs, outputs: text_not_text_outputs, network: text_not_network, encoded_inputs: text_not_inputs },
  { name: "NAND", inputs: text_nand_text_inputs, outputs: text_nand_text_outputs, network: text_nand_network, encoded_inputs: text_nand_inputs },
  { name: "NOR", inputs: text_nor_text_inputs, outputs: text_nor_text_outputs, network: text_nor_network, encoded_inputs: text_nor_inputs }
]

all_networks.each do |net_info|
  correct = 0
  total = net_info[:inputs].length
  
  net_info[:inputs].each_with_index do |input_text, i|
    input_vector = net_info[:encoded_inputs][i]
    output_vector = net_info[:network].run(input_vector)
    snapped = snap_to_one_hot(output_vector)
    predicted_text = decode_bool(snapped)
    actual_text = net_info[:outputs][i]
    
    correct += 1 if predicted_text == actual_text
  end
  
  percentage = (correct.to_f / total * 100).round(1)
  marker = correct == total ? "‚úÖ" : "‚ö†Ô∏è"
  puts "#{marker} #{net_info[:name]}: #{correct}/#{total} (#{percentage}%)"
end

puts "\nüéâ Successfully trained neural networks to understand TEXT!"

puts "From numbers to words - this is a major milestone in development! üöÄ"

text_models = {
  and: { shape: text_and_network.shape, weights: text_and_network.weights },
  or: { shape: text_or_network.shape, weights: text_or_network.weights },
  xor: { shape: text_xor_network.shape, weights: text_xor_network.weights },
  not: { shape: text_not_network.shape, weights: text_not_network.weights },
  nand: { shape: text_nand_network.shape, weights: text_nand_network.weights },
  nor: { shape: text_nor_network.shape, weights: text_nor_network.weights }
}

def iterative_snap_to_correct(predicted, valid_outputs, actual, max_steps: 10)
  steps = [predicted]
  current = predicted
  
  max_steps.times do
    # Snap to nearest valid
    snapped = valid_outputs.min_by { |valid| (current - valid).abs }
    steps << snapped
    
    # If we hit the target, stop
    if (snapped - actual).abs < 0.001
      return { final: snapped, steps: steps, success: true }
    end
    
    # Calculate direction to move
    error = actual - snapped
    
    # Find next valid output in the direction we need to go
    if error > 0
      # Need to go UP
      next_valid = valid_outputs.select { |v| v > snapped }.min
    else
      # Need to go DOWN
      next_valid = valid_outputs.select { |v| v < snapped }.max
    end
    
    # If no next valid in that direction, we're stuck
    if next_valid.nil?
      # Try pushing current value in the right direction
      current = current + (error * 0.5)
      steps << current
    else
      # Move current toward next valid
      current = (current + next_valid) / 2.0
      steps << current
    end
  end
  
  # Final snap
  final = valid_outputs.min_by { |valid| (current - valid).abs }
  { final: final, steps: steps, success: (final - actual).abs < 0.001 }
end

# Add a new decoder for yes/no:
def decode_yesno(vector)
  if vector[0] > vector[1]
    "yes"
  else
    "no"
  end
end

puts "\n" + "="*80
puts "TESTING YES/NO WITH SAME NETWORKS!"
puts "="*80
puts "The networks already understand binary logic - just testing new vocabulary!"
puts "="*80

# Test YES/NO with the existing trained networks
yesno_test_inputs = [
  ["no", "no"],
  ["no", "yes"],
  ["yes", "no"],
  ["yes", "yes"]
]

puts "\nAND GATE - Yes/No Test (using existing text_and_network):"
yesno_test_inputs.each do |pair|
  input_vector = encode_bool(pair[0]) + encode_bool(pair[1])
  output_vector = text_and_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted = decode_yesno(snapped)
  
  # Expected outputs for AND
  expected = (pair[0] == "yes" && pair[1] == "yes") ? "yes" : "no"
  marker = predicted == expected ? "‚úì" : "‚úó"
  
  puts "  #{marker} \"#{pair[0]}\" AND \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted}\" (expected: \"#{expected}\")"
end

puts "\nOR GATE - Yes/No Test (using existing text_or_network):"
yesno_test_inputs.each do |pair|
  input_vector = encode_bool(pair[0]) + encode_bool(pair[1])
  output_vector = text_or_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted = decode_yesno(snapped)
  
  # Expected outputs for OR
  expected = (pair[0] == "yes" || pair[1] == "yes") ? "yes" : "no"
  marker = predicted == expected ? "‚úì" : "‚úó"
  
  puts "  #{marker} \"#{pair[0]}\" OR \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted}\" (expected: \"#{expected}\")"
end

puts "\nXOR GATE - Yes/No Test (using existing text_xor_network):"
yesno_test_inputs.each do |pair|
  input_vector = encode_bool(pair[0]) + encode_bool(pair[1])
  output_vector = text_xor_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted = decode_yesno(snapped)
  
  # Expected outputs for XOR
  expected = (pair[0] != pair[1]) ? "yes" : "no"
  marker = predicted == expected ? "‚úì" : "‚úó"
  
  puts "  #{marker} \"#{pair[0]}\" XOR \"#{pair[1]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted}\" (expected: \"#{expected}\")"
end

yesno_single_inputs = [["no"], ["yes"]]

puts "\nNOT GATE - Yes/No Test (using existing text_not_network):"
yesno_single_inputs.each do |arr|
  input_vector = encode_bool(arr[0])
  output_vector = text_not_network.run(input_vector)
  snapped = snap_to_one_hot(output_vector)
  predicted = decode_yesno(snapped)
  
  # Expected outputs for NOT
  expected = arr[0] == "yes" ? "no" : "yes"
  marker = predicted == expected ? "‚úì" : "‚úó"
  
  puts "  #{marker} NOT \"#{arr[0]}\" = #{output_vector.map{|v| v.round(3)}.inspect} ‚Üí \"#{predicted}\" (expected: \"#{expected}\")"
end

puts "\n" + "="*80
puts "BILINGUAL NEURAL NETWORK! üåç"
puts "="*80
puts "‚úÖ Same networks understand BOTH true/false AND yes/no!"
puts "‚úÖ No retraining needed - just vocabulary mapping!"
puts "üéâ The network learned the CONCEPT, not just the words!"
puts "="*80

puts "\n" + "="*80
puts "FACTORIAL MODEL - NATURAL DECIMAL MAPPING"
puts "="*80
puts "Concept: n! = result, naturally represented as decimals"
puts "Example: 5! = 120, input 0.5, output 0.120"
puts "No division needed - numbers naturally fit in 0-1 range!"
puts "="*80

factorial_network = NeuralNet.new([1, 60, 60, 1])

# Factorial examples: Natural decimal representation
# Format: [input] ‚Üí output
# Input: 0.n representing n
# Output: factorial result as decimal

factorial_inputs = [
  [0.1],  # 1! = 1 ‚Üí 0.001
  [0.2],  # 2! = 2 ‚Üí 0.002
  [0.3],  # 3! = 6 ‚Üí 0.006
  [0.4],  # 4! = 24 ‚Üí 0.024
  [0.5],  # 5! = 120 ‚Üí 0.120
  [0.6],  # 6! = 720 ‚Üí 0.720
]

# Calculate outputs: just write factorial as decimal!
factorial_outputs = [
  [0.001],   # 1
  [0.002],   # 2
  [0.006],   # 6
  [0.024],   # 24
  [0.120],   # 120
  [0.720],   # 720
]

# Show what we're learning
puts "\nFactorial Training Set (Natural Decimal Mapping):"
factorial_inputs.each_with_index do |input, i|
  n = (input[0] * 10).round
  result = factorial_outputs[i][0]
  result_whole = (result * 1000).round
  puts "  #{input[0]}! ‚Üí #{factorial_outputs[i][0]} (thinking: #{n}! = #{result_whole})"
end

valid_factorial_results = factorial_outputs.map { |o| o[0] }.uniq.sort
puts "\nValid factorial outputs: #{valid_factorial_results.map { |x| x.round(3) }.inspect}"

puts "\nIterative Progressive Snapping Training"

base_iterations = 500
max_rounds = 5

max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    factorial_network.train(factorial_inputs, factorial_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  factorial_inputs.each_with_index do |input, i|
    predicted = factorial_network.run(input)[0]
    actual = factorial_outputs[i][0]
      result = iterative_snap_to_correct(predicted, valid_factorial_results, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.001
      wrong_cases << { index: i, result: result }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.001 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      i = case_data[:index]
      input = factorial_inputs[i]
      actual = factorial_outputs[i][0]
      steps = case_data[:result][:steps]
      
      n = (input[0] * 10).round
      result_whole = (actual * 1000).round
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << input
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    #{input[0]}!: #{steps.length} steps ‚Üí #{case_data[:result][:final].round(3)} (need #{actual.round(3)}) | {#{n}! = #{result_whole}}"
    end
    
    1500.times do
      factorial_network.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      factorial_network.train(factorial_inputs, factorial_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.001
    puts "\nüéØüéØüéØ FACTORIAL PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 100
end

puts "\n" + "="*80
puts "FACTORIAL PREDICTIONS (Final with Iterative Snapping Path)"
puts "="*80

factorial_inputs.each_with_index do |input, i|
  predicted = factorial_network.run(input)[0]
  actual = factorial_outputs[i][0]
  result = iterative_snap_to_correct(predicted, valid_factorial_results, actual)
  
  error = (result[:final] - actual).abs
  marker = error < 0.001 ? "‚úì" : "‚úó"
  
  # Show interpretation
  n = (input[0] * 10).round
  result_decimal = result[:final]
  result_whole = (result_decimal * 1000).round
  actual_whole = (actual * 1000).round
  
  path_str = result[:steps][0..3].map { |s| s.round(3) }.join(" ‚Üí ")
  if result[:steps].length > 4
    path_str += " ‚Üí ... ‚Üí #{result[:final].round(3)}"
  else
    path_str += " ‚Üí #{result[:final].round(3)}"
  end
  
  puts "  #{marker} #{input[0]}! = #{path_str} (actual: #{actual.round(3)}, error: #{error.round(4)})"
  puts "      Thinking: #{n}! = #{result_whole} (should be #{actual_whole})"
end
=end
def iterative_snap_to_correct(predicted, valid_outputs, actual, max_steps: 10)
  steps = [predicted]
  current = predicted
  
  max_steps.times do
    # Snap to nearest valid
    snapped = valid_outputs.min_by { |valid| (current - valid).abs }
    steps << snapped
    
    # If we hit the target, stop
    if (snapped - actual).abs < 0.01
      return { final: snapped, steps: steps, success: true }
    end
    
    # Calculate direction to move
    error = actual - snapped
    
    # Find next valid output in the direction we need to go
    if error > 0
      # Need to go UP
      next_valid = valid_outputs.select { |v| v > snapped }.min
    else
      # Need to go DOWN
      next_valid = valid_outputs.select { |v| v < snapped }.max
    end
    
    # If no next valid in that direction, we're stuck
    if next_valid.nil?
      # Try pushing current value in the right direction
      current = current + (error * 0.5)
      steps << current
    else
      # Move current toward next valid
      current = (current + next_valid) / 2.0
      steps << current
    end
  end
  
  # Final snap
  final = valid_outputs.min_by { |valid| (current - valid).abs }
  { final: final, steps: steps, success: (final - actual).abs < 0.01 }
end

puts "\n" + "="*80
puts "WORD DECIMAL MAPPING - WITH ITERATIVE PROGRESSIVE SNAPPING"
puts "="*80
puts "Using the proven technique that achieved 100% accuracy on arithmetic!"
puts "="*80

# ============================================================================
# SENTIMENT CLASSIFICATION (20 words ‚Üí 3 categories)
# ============================================================================

SENTIMENT_WORDS = {
  # Positive emotions (0.01-0.09)
  "happy" => 0.01,
  "joy" => 0.02,
  "excited" => 0.03,
  "wonderful" => 0.04,
  "amazing" => 0.05,
  "great" => 0.06,
  "love" => 0.07,
  "excellent" => 0.08,
  
  # Negative emotions (0.11-0.19)
  "sad" => 0.11,
  "angry" => 0.12,
  "terrible" => 0.13,
  "awful" => 0.14,
  "bad" => 0.15,
  "hate" => 0.16,
  "horrible" => 0.17,
  "worst" => 0.18,
  
  # Neutral (0.51-0.54)
  "okay" => 0.51,
  "fine" => 0.52,
  "alright" => 0.53,
  "neutral" => 0.54
}

SENTIMENT_LABELS = {
  "positive" => 0.9,
  "negative" => 0.1,
  "neutral" => 0.5
}

puts "\n" + "="*80
puts "SENTIMENT ANALYSIS - Iterative Progressive Snapping"
puts "="*80

sentiment_network = NeuralNet.new([1, 60, 60, 1])

# Prepare training data
sentiment_training = []
SENTIMENT_WORDS.each do |word, word_value|
  if word_value <= 0.09
    sentiment_training << { word: word, input: word_value, output: SENTIMENT_LABELS["positive"] }
  elsif word_value <= 0.19
    sentiment_training << { word: word, input: word_value, output: SENTIMENT_LABELS["negative"] }
  else
    sentiment_training << { word: word, input: word_value, output: SENTIMENT_LABELS["neutral"] }
  end
end

sentiment_inputs = sentiment_training.map { |t| [t[:input]] }
sentiment_outputs = sentiment_training.map { |t| [t[:output]] }
valid_sentiments = SENTIMENT_LABELS.values

base_iterations = 400
max_rounds = 30

puts "\nIterative Progressive Snapping Training"

max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    sentiment_network.train(sentiment_inputs, sentiment_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  sentiment_training.each_with_index do |t, i|
    predicted = sentiment_network.run([t[:input]])[0]
    actual = t[:output]
    result = iterative_snap_to_correct(predicted, valid_sentiments, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result, training: t }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      t = case_data[:training]
      actual = t[:output]
      steps = case_data[:result][:steps]
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << [t[:input]]
        all_progressive_outputs << [progressive_target]
      end
      
      actual_label = SENTIMENT_LABELS.key(actual)
      puts "    \"#{t[:word]}\": #{steps.length} steps ‚Üí #{case_data[:result][:final].round(2)} (need #{actual.round(2)} for #{actual_label})"
    end
    
    1500.times do
      sentiment_network.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      sentiment_network.train(sentiment_inputs, sentiment_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ SENTIMENT PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 50
end

puts "\nSENTIMENT PREDICTIONS:"
correct = 0
sentiment_training.each do |t|
  predicted = sentiment_network.run([t[:input]])[0]
  result = iterative_snap_to_correct(predicted, valid_sentiments, t[:output])
  
  predicted_label = SENTIMENT_LABELS.key(result[:final])
  actual_label = SENTIMENT_LABELS.key(t[:output])
  error = (result[:final] - t[:output]).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  correct += 1 if error < 0.01
  
  puts "  #{marker} \"#{t[:word]}\" (#{t[:input]}) ‚Üí #{predicted.round(3)} ‚Üí \"#{predicted_label}\" (actual: \"#{actual_label}\")"
end

percentage = (correct.to_f / sentiment_training.length * 100).round(1)
puts "\n‚úÖ Sentiment Accuracy: #{correct}/#{sentiment_training.length} (#{percentage}%)"

# ============================================================================
# ANIMAL SOUNDS (10 animals ‚Üí 10 sounds) - WITH WIDER SPACING!
# ============================================================================

ANIMALS = {
  "cat" => 0.01,
  "dog" => 0.02,
  "bird" => 0.03,
  "cow" => 0.04,
  "duck" => 0.05,
  "horse" => 0.06,
  "pig" => 0.07,
  "sheep" => 0.08,
  "lion" => 0.09,
  "frog" => 0.10
}

# WIDER SPACING - 0.1 apart instead of 0.01!
SOUNDS = {
  "meow" => 0.10,
  "woof" => 0.20,
  "chirp" => 0.30,
  "moo" => 0.40,
  "quack" => 0.50,
  "neigh" => 0.60,
  "oink" => 0.70,
  "baa" => 0.80,
  "roar" => 0.90,
  "ribbit" => 1.00
}

puts "\n" + "="*80
puts "ANIMAL SOUNDS - Iterative Progressive Snapping (WIDER SPACING)"
puts "="*80

animal_sound_network = NeuralNet.new([1, 60, 60, 1])

# Create training pairs
animal_sound_pairs = [
  ["cat", "meow"],
  ["dog", "woof"],
  ["bird", "chirp"],
  ["cow", "moo"],
  ["duck", "quack"],
  ["horse", "neigh"],
  ["pig", "oink"],
  ["sheep", "baa"],
  ["lion", "roar"],
  ["frog", "ribbit"]
]

animal_inputs = animal_sound_pairs.map { |animal, _| [ANIMALS[animal]] }
sound_outputs = animal_sound_pairs.map { |_, sound| [SOUNDS[sound]] }
valid_sounds = SOUNDS.values

base_iterations = 400
max_rounds = 30

puts "\nIterative Progressive Snapping Training"

max_rounds.times do |round|
  puts "\n--- Round #{round + 1}/#{max_rounds} (#{base_iterations} iterations) ---"
  
  base_iterations.times do
    animal_sound_network.train(animal_inputs, sound_outputs, max_iterations: 10000)
  end
  
  errors = []
  wrong_cases = []
  animal_sound_pairs.each_with_index do |(animal, actual_sound), i|
    predicted = animal_sound_network.run([ANIMALS[animal]])[0]
    actual = SOUNDS[actual_sound]
    result = iterative_snap_to_correct(predicted, valid_sounds, actual)
    
    error = (result[:final] - actual).abs
    errors << error
    
    if error > 0.01
      wrong_cases << { index: i, result: result, animal: animal, sound: actual_sound }
    end
  end
  
  perfect_count = errors.count { |e| e < 0.01 }
  avg_error = errors.sum / errors.length
  max_error = errors.max
  
  puts "Perfect: #{perfect_count}/#{errors.length}, Avg: #{avg_error.round(4)}, Max: #{max_error.round(4)}"
  
  if wrong_cases.any?
    puts "  ‚ö†Ô∏è  #{wrong_cases.length} cases wrong - Training on PROGRESSIVE PATH!"
    
    all_progressive_inputs = []
    all_progressive_outputs = []
    
    wrong_cases.each do |case_data|
      animal = case_data[:animal]
      actual_sound = case_data[:sound]
      actual = SOUNDS[actual_sound]
      steps = case_data[:result][:steps]
      
      steps.each_with_index do |step, step_idx|
        progress = (step_idx + 1).to_f / steps.length
        progressive_target = step + (actual - step) * (0.3 + progress * 0.7)
        
        all_progressive_inputs << [ANIMALS[animal]]
        all_progressive_outputs << [progressive_target]
      end
      
      puts "    \"#{animal}\": #{steps.length} steps ‚Üí #{case_data[:result][:final].round(2)} (need #{actual.round(2)} for #{actual_sound})"
    end
    
    1500.times do
      animal_sound_network.train(all_progressive_inputs, all_progressive_outputs, max_iterations: 10000)
    end
    
    400.times do
      animal_sound_network.train(animal_inputs, sound_outputs, max_iterations: 10000)
    end
  end
  
  if max_error < 0.01
    puts "\nüéØüéØüéØ ANIMAL SOUNDS PERFECTION ACHIEVED! üéØüéØüéØ"
    break
  end
  
  base_iterations += 50
end

puts "\nANIMAL SOUND PREDICTIONS:"
correct = 0
animal_sound_pairs.each do |(animal, actual_sound)|
  predicted = animal_sound_network.run([ANIMALS[animal]])[0]
  actual = SOUNDS[actual_sound]
  result = iterative_snap_to_correct(predicted, valid_sounds, actual)
  
  predicted_sound = SOUNDS.key(result[:final])
  error = (result[:final] - actual).abs
  marker = error < 0.01 ? "‚úì" : "‚úó"
  correct += 1 if error < 0.01
  
  puts "  #{marker} \"#{animal}\" (#{ANIMALS[animal]}) ‚Üí #{predicted.round(3)} ‚Üí \"#{predicted_sound}\" (actual: \"#{actual_sound}\")"
end

percentage = (correct.to_f / animal_sound_pairs.length * 100).round(1)
puts "\n‚úÖ Animal Sound Accuracy: #{correct}/#{animal_sound_pairs.length} (#{percentage}%)"

# ============================================================================
# SUMMARY
# ============================================================================

puts "\n" + "="*80
puts "SUMMARY - ITERATIVE PROGRESSIVE SNAPPING FOR WORDS"
puts "="*80
puts "üéØ Used the proven technique from arithmetic operations!"
puts "üöÄ KEY INSIGHT: Wider spacing (0.1 apart) for one-to-one mappings!"
puts "="*80
=begin
model_data = {
  shape: network.shape,
  weights: network.weights
}

and_model_data = {
    shape: and_xor_network.shape,
    weights: and_xor_network.weights
}

or_model_data = {
    shape: or_xor_network.shape,
    weights: or_xor_network.weights
}

nand_model_data = {
    shape: nand_network.shape,
    weights: nand_network.weights
}

nor_model_data = {
    shape: nor_network.shape,
    weights: nor_network.weights
}

xnor_model_data = {
    shape: xnor_network.shape,
    weights: xnor_network.weights
}

max_model_data = {
    function: "max",
    shape: max_network.shape,
    weights: max_network.weights
}

min_model_data = {
    function: "min",
    shape: min_network.shape,
    weights: min_network.weights
}

add_model_data = {
    function: "add",
    shape: addition_network.shape,
    weights: addition_network.weights
}

sub_model_data = {
    function: "subtract",
    shape: subtraction_nn.shape,
    weights: subtraction_nn.weights
}

mul_model_data = {
    function: "multiply",
    shape: multiplication_nn.shape,
    weights: multiplication_nn.weights
}

# Save the model
division_model_data = {
  function: "divide",
  concept: "whole_number_decimal_representation",
  shape: division_network.shape,
  weights: division_network.weights
}

# Save the model
division_model_data = {
  function: "divide",
  concept: "whole_number_decimal_representation",
  shape: division_network.shape,
  weights: division_network.weights
}

exponent_model_data = {
  function: "exponent",
  operation: "square",
  concept: "n_squared_div_100_mapping",
  shape: exponent_network.shape,
  weights: exponent_network.weights
}

factorial_model_data = {
  function: "factorial",
  concept: "natural_decimal_representation",
  shape: factorial_network.shape,
  weights: factorial_network.weights
}
=end
word_mappings = {
  sentiment_words: SENTIMENT_WORDS,
  sentiment_labels: SENTIMENT_LABELS,
  animals: ANIMALS,
  sounds: SOUNDS
  #objects: OBJECTS,
  #colors: COLORS,
  #items: ITEMS,
  #categories: CATEGORIES
}

sentiment_model_data = {
    function: "sentiment",
    shape: sentiment_network.shape,
    weights: sentiment_network.weights
}

animal_model_data = {
    function: "animals_and_their_sounds",
    shape: animal_sound_network.shape,
    weights: animal_sound_network.weights
}
=begin
File.write("model.json", JSON.pretty_generate(model_data))
File.write("and_model.json", JSON.pretty_generate(and_model_data))
File.write("or_model.json", JSON.pretty_generate(or_model_data))
File.write("nand_model.json", JSON.pretty_generate(nand_model_data))
File.write("nor_network.json", JSON.pretty_generate(nor_model_data))
File.write("xnor_network.json", JSON.pretty_generate(xnor_model_data))
File.write("max_model_.json", JSON.pretty_generate(max_model_data))
File.write("min_model.json", JSON.pretty_generate(min_model_data))
File.write("exponent_model.json", JSON.pretty_generate(exponent_model_data))
File.write("addition_model.json", JSON.pretty_generate(add_model_data))
File.write("subtraction_model.json", JSON.pretty_generate(sub_model_data))
File.write("multiplication_model.json", JSON.pretty_generate(mul_model_data))
File.write("division_model.json", JSON.pretty_generate(division_model_data))
File.write("exponent_model.json", JSON.pretty_generate(exponent_model_data))
File.write("text_boolean_models.json", JSON.pretty_generate(text_models))
File.write("factorial_model.json", JSON.pretty_generate(factorial_model_data))
=end
File.write("word_decimal_mappings.json", JSON.pretty_generate(word_mappings))
File.write("sentiment_model.json", JSON.pretty_generate(sentiment_model_data))
File.write("animal_model.json", JSON.pretty_generate(animal_model_data))
